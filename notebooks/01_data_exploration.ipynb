{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a90528",
   "metadata": {},
   "source": [
    "## 01 Data Exploration\n",
    "\n",
    "In this notebook, I imported 2 datasets to explore the data available. I combine these 2 datasets to be used to train my distilBERT model in 02_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d98613",
   "metadata": {},
   "source": [
    "### Dataset: [allenai/wildjailbreak](https://huggingface.co/datasets/allenai/wildjailbreak)\n",
    "\n",
    "This dataset contains vanilla and adversarial prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "\n",
    "train = pd.read_csv(\"hf://datasets/allenai/wildjailbreak/train/train.tsv\", sep=\"\\t\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c010c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data available by data type\n",
    "train.groupby(by='data_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check why there are lesser adversarial than vanilla for adversarial_benign\n",
    "\n",
    "mask = (train['data_type'] == 'adversarial_benign') & train['adversarial'].isna()\n",
    "print(train.loc[mask].shape)\n",
    "display(train.loc[mask, ['vanilla','adversarial','completion', 'data_type']].head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and duplicates.\n",
    "train_df = train.copy().rename(columns = {'data_type' : 'label'})\n",
    "\n",
    "print(\"NA:\", train_df.isna().sum())\n",
    "print(\"Duplicated:\", train_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows from adversarial_benign that have NaN in adversarial\n",
    "train_df.drop(index=train_df[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db72d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rows have both vanilla and adversarial prompts. \n",
    "# Combine the rows into one column: prompt\n",
    "\n",
    "train_df['prompt'] = train_df['adversarial'].fillna(train_df['vanilla'])\n",
    "\n",
    "# Take necessary columns\n",
    "columns = ['prompt', 'label']\n",
    "train_df = train_df[columns]\n",
    "\n",
    "# Check\n",
    "train_df.groupby(by='label').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in prompt\n",
    "print(train_df.duplicated().sum())\n",
    "print(train_df.loc[train_df.duplicated() == True])\n",
    "\n",
    "# Drop duplicates\n",
    "train_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc92618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some examples by data type\n",
    "\n",
    "for t in train_df['label'].unique():\n",
    "    display(t, train_df.loc[train_df['label']==t].sample(3, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsize_by_min(df):\n",
    "    min_class_size = df['label'].value_counts().min()\n",
    "\n",
    "    # Select all columns except the grouping one manually\n",
    "    balanced_df = df.groupby('label', group_keys=False)[['prompt', 'label']].apply(\n",
    "        lambda x: x.sample(min_class_size, random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(balanced_df['label'].value_counts())\n",
    "    return balanced_df\n",
    "\n",
    "balanced_train_df = downsize_by_min(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_wordcount(df):\n",
    "    # Calculate word count for each prompt\n",
    "    data = df.copy()\n",
    "    data['word_count'] = data['prompt'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # Visualize length distribution by label\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=data, x='word_count', hue='label', element=\"step\")\n",
    "    plt.title(\"Prompt Length Distribution by Class\")\n",
    "    plt.xlim(0, data['word_count'].max()) \n",
    "    plt.show()\n",
    "\n",
    "plot_wordcount(balanced_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6df986",
   "metadata": {},
   "source": [
    "The vanilla classes have shorter prompts as compared to adversarial prompts. My decision: choose longer vanilla prompts and shorter adversarial prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00018c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_aware_sample(df, target_size):\n",
    "    balanced_chunks = []\n",
    "    \n",
    "    for cat in df['label'].unique():\n",
    "        cat_group = df[df['label'] == cat].copy()\n",
    "        cat_group['word_count'] = cat_group['prompt'].str.split().str.len()\n",
    "        \n",
    "        # Sort logic: \n",
    "        # For vanilla: Keep the longest (to bridge the gap toward adversarial)\n",
    "        # For adversarial: Keep the shortest (to bridge the gap toward vanilla)\n",
    "        if 'vanilla' in cat:\n",
    "            cat_group = cat_group.sort_values('word_count', ascending=False)\n",
    "        else:\n",
    "            cat_group = cat_group.sort_values('word_count', ascending=True)\n",
    "            \n",
    "        # Take the top N samples based on this priority\n",
    "        balanced_chunks.append(cat_group.head(target_size))\n",
    "        \n",
    "    return pd.concat(balanced_chunks).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Apply the sampler\n",
    "final_train_df = length_aware_sample(balanced_train_df, 40000)\n",
    "plot_wordcount(final_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df.groupby(by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and shuffle\n",
    "jailbreak = final_train_df.copy().sample(frac=1).reset_index(drop=True)\n",
    "jailbreak.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1adae0",
   "metadata": {},
   "source": [
    "### Dataset: [nvidia/Aegis-AI-Content-Safety-Dataset-2.0](https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8047198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'train.json', 'validation': 'validation.json', 'test': 'test.json'}\n",
    "train2 = pd.read_json(\"hf://datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0/\" + splits[\"train\"])\n",
    "test2 = pd.read_json(\"hf://datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0/\" + splits[\"test\"]) \n",
    "data = pd.concat([test2, train2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5dd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2.shape)\n",
    "print(test2.shape)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e40855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out reconstruction\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Load the latest version\n",
    "sw = kagglehub.load_dataset(\n",
    "KaggleDatasetAdapter.PANDAS,\n",
    "\"nikhileswarkomati/suicide-watch\",\n",
    "\"Suicide_Detection.csv\",\n",
    ")\n",
    "\n",
    "suicide_text_map = sw.set_index('Unnamed: 0')['text'].to_dict()\n",
    "\n",
    "\n",
    "def reconstruct_prompt(row):\n",
    "    # Check if the prompt is redacted and we have a valid reconstruction ID\n",
    "    if row['prompt'] == \"REDACTED\" and pd.notnull(row['reconstruction_id_if_redacted']):\n",
    "        # Pull the original text from our map using the ID\n",
    "        return suicide_text_map.get(int(row['reconstruction_id_if_redacted']))\n",
    "    return row['prompt']\n",
    "\n",
    "# Apply the reconstruction\n",
    "data['prompt'] = data.apply(reconstruct_prompt, axis=1)\n",
    "\n",
    "print(f\"Reconstructed {data[data['prompt'] != 'REDACTED'].shape[0]} prompts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfdad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing only required columns\n",
    "columns = ['prompt', 'prompt_label']\n",
    "data_df = data[columns].copy().rename(columns={'prompt_label': 'label'})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f23d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and duplicates\n",
    "print(data_df.isna().sum())\n",
    "print(data_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_labelled = pd.DataFrame(data_df.duplicated(keep='first'), columns=['duplicate'])\n",
    "\n",
    "combined = duplicates_labelled.join(data_df)\n",
    "\n",
    "print('Duplicate rows (taking both columns into account)\\n')\n",
    "print(combined.groupby('duplicate').count())\n",
    "print('\\nUnique prompts\\n')\n",
    "print(combined.groupby('duplicate')['prompt'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9696445",
   "metadata": {},
   "source": [
    "All Rows (count):\n",
    "\n",
    "False 29784: These are the \"Originals\" (the first time these rows appear).\n",
    "\n",
    "True 1115: These are exact \"Carbon Copies\" (identical row content).\n",
    "\n",
    "Unique Prompts (nunique):\n",
    "\n",
    "\n",
    "False 25691: Out of 29784 \"Original\" rows, only 25691 are unique text strings.\n",
    "\n",
    "The Conflict: 29784âˆ’25691=4093. The same prompt with different labels will not be marked as duplicate when duplicate() is applied to the whole dateframe. This means there are 4093 prompts in dataset that have identical text but different labels (e.g., one row says \"Safe\" and another says \"Unsafe\" for the exact same sentence).\n",
    "\n",
    "Example\n",
    "\n",
    "prompt1 = \"Hello\" label1 = 'Safe'\n",
    "prompt2 = \"Hello\" label2 = 'Unsafe\n",
    "\n",
    "The rows are not duplicates but the prompts are not unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c23b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if any prompt has more than one unique label\n",
    "combined.groupby('prompt')['label'].nunique().gt(1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe method: Whichever prompts are labelled both safe and unsafe, take unsafe\n",
    "\n",
    "# those labelled unsafe are kept\n",
    "data_df = data_df.sort_values(by='label', ascending=False)\n",
    "\n",
    "\n",
    "# Drop duplicates based on the text column \n",
    "\n",
    "cleaned_df = data_df.drop_duplicates(subset=['prompt'], keep='first')\n",
    "\n",
    "# Verify\n",
    "print(f\"Total rows after strict cleaning: {len(cleaned_df)}\")\n",
    "print(f\"Total unique prompts: {cleaned_df['prompt'].nunique()}\")\n",
    "# These two numbers should now be same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ffd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcount(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df2 = length_aware_sample(cleaned_df, 11000)\n",
    "plot_wordcount(final_train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df2.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae12ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aegis = final_train_df2.copy().sample(frac=1).reset_index(drop=True)\n",
    "aegis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cde750",
   "metadata": {},
   "source": [
    "### Combine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d78006",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([aegis, jailbreak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30013095",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_class_size = combined['label'].value_counts().min()\n",
    "\n",
    "# Select all columns except the grouping one manually\n",
    "balanced_df = combined.groupby('label', group_keys=False)[['prompt', 'label']].apply(\n",
    "    lambda x: x.sample(min_class_size, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "balanced_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcount(balanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19575541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns to safe & unsafe\n",
    "\n",
    "label_map = {\n",
    "    'adversarial_benign': 0,\n",
    "    'vanilla_benign': 0,\n",
    "    'safe': 0,\n",
    "    'adversarial_harmful': 1,\n",
    "    'vanilla_harmful': 1,\n",
    "    'unsafe': 1\n",
    "}\n",
    "\n",
    "balanced_df['label'] = balanced_df['label'].map(label_map)\n",
    "balanced_df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
