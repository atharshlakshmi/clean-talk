{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0ba932",
   "metadata": {},
   "source": [
    "## 02 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0481e",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d644f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, DistilBertTokenizer\n",
    "from tqdm.auto import tqdm # For a nice progress bar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Adds the parent directory to the python path\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "from src.core.features import clean_aegis, clean_jailbreak, merge_data\n",
    "from src.utils.logger import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247e81d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load & clean Aegis data\n",
    "splits = {'train': 'train.json', 'validation': 'validation.json', 'test': 'test.json'}\n",
    "train = pd.read_json(\"hf://datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0/\" + splits[\"train\"])\n",
    "test = pd.read_json(\"hf://datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0/\" + splits[\"test\"]) \n",
    "\n",
    "aegis_clean = clean_aegis(train, train)\n",
    "print(f\"Aegis data shape: {aegis_clean.shape}\")\n",
    "\n",
    "#Load & clean jailbreak data\n",
    "jailbreak = pd.read_csv(\"hf://datasets/allenai/wildjailbreak/train/train.tsv\", sep=\"\\t\")\n",
    "\n",
    "jailbreak_clean = clean_jailbreak(jailbreak)\n",
    "print(f\"Jailbreak data shape: {jailbreak_clean.shape}\")\n",
    "\n",
    "# Merge, encode and tokenise\n",
    "data = merge_data(jailbreak_clean, aegis_clean)\n",
    "\n",
    "# Dictionary to map strings to numbers\n",
    "id2label = {i: name for i, name in enumerate(data['label'].unique())}\n",
    "label2id = {name: i for i, name in id2label.items()}\n",
    "\n",
    "# Apply to your dataframe\n",
    "data['label'] = data['label'].map(label2id)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d368f",
   "metadata": {},
   "source": [
    "### Create data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(\n",
    "    data, \n",
    "    test_size=0.10, \n",
    "    stratify=data['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, \n",
    "    test_size=(1/9), \n",
    "    stratify=train_val_df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1111886",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
    "                                                           num_labels=6,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# freeze all base model parameters\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unfreeze base model pooling layers\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"pooler\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61809ba",
   "metadata": {},
   "source": [
    "### Tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e742ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"prompt\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "train_ds.set_format(\"torch\")\n",
    "\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "val_ds.set_format(\"torch\")\n",
    "\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "test_ds.set_format(\"torch\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba727293",
   "metadata": {},
   "source": [
    "### Training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size = 16, shuffle = True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size = 16, shuffle = True, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "def train(num_epoch, logger, model_save_path):\n",
    "    best_f1 = 0\n",
    "    for epoch in range(num_epoch):\n",
    "        print(f\"\\n--- Epoch {epoch + 1} ---\")\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for batch, data in enumerate(train_loader):\n",
    "            input_ids = data['input_ids']\n",
    "            attention_mask = data['attention_mask']\n",
    "            labels = data['label']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            train_preds.extend(preds.cpu().detach().numpy())\n",
    "            train_labels.extend(labels.cpu().detach().numpy())\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
    "        \n",
    "        total_val_loss = 0\n",
    "        correct_predictions = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                input_ids = data['input_ids']\n",
    "                attention_mask = data['attention_mask']\n",
    "                labels = data['label']\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, labels)\n",
    "                total_val_loss += loss.item()\n",
    "            \n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                val_preds.extend(preds.cpu().detach().numpy())\n",
    "                val_labels.extend(labels.cpu().detach().numpy())\n",
    "                correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            val_acc = correct_predictions.double() / len(val_ds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        # LOGGING \n",
    "        epoch_metrics = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_f1': train_f1,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_f1': val_f1,\n",
    "            'accuracy': val_acc.item(),\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        logger.log(epoch_metrics)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved. New best F1: {val_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffcc6a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aea196",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_num = 1\n",
    "time_start = datetime.today().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "for i in range(training_num):\n",
    "    logger = Logger(f'{time_start}_training{i}.csv')\n",
    "    \n",
    "    model_save_path = f'models/{time_start}_best_model_run_{i}.pt'\n",
    "\n",
    "    train(3, logger, model_save_path)\n",
    "    \n",
    "    logger.visualise()\n",
    "    best_stats = logger.end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a449d",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_ds, batch_size = 16, shuffle = True, num_workers=2)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6)\n",
    "model.load_state_dict(torch.load('best_model_weights.pt'))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move to device\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(ids, attention_mask=mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        \n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(test_labels, test_preds, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53dcef",
   "metadata": {},
   "source": [
    "### Visualise model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Assuming you have 'test_labels' and 'test_preds' from your test loop\n",
    "categories = [\n",
    "    'vanilla_benign', 'vanilla_harmful', \n",
    "    'adversarial_benign', 'adversarial_harmful', \n",
    "    'safe', 'unsafe'\n",
    "]\n",
    "\n",
    "# 2. Generate the matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# 3. Create a clean Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues', \n",
    "    xticklabels=categories, yticklabels=categories\n",
    ")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Clean-Talk Guardrail: Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4. Print the full report for precision/recall per class\n",
    "print(classification_report(test_labels, test_preds, target_names=data['label'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
